# site_analyzer.py
import requests
from bs4 import BeautifulSoup
import whois
from datetime import datetime, timedelta
import re
from urllib.parse import urlparse
import logging
import ssl
import socket
from urllib.parse import urlunparse

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class SiteAnalyzer:
    def __init__(self):
        self.results = {}
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }

    def analyze_site(self, url):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ —Å–∞–π—Ç–∞"""
        try:
            if not self.is_valid_url(url):
                return "‚ùå –û—à–∏–±–∫–∞: –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL"

            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ—Ç–æ–∫–æ–ª –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º HTTPS
            url = self.normalize_and_check_protocol(url)

            domain = self.extract_domain(url)
            logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ —Å–∞–π—Ç–∞: {domain}")

            # –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            self.results.clear()

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ HTTPS (–≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–µ—Ä–≤–æ–π)
            self.check_https_security(url, domain)

            # –í—ã–ø–æ–ª–Ω—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
            self.check_domain_age(domain)

            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç —Å–∞–π—Ç–∞
            try:
                response = requests.get(url, headers=self.headers, timeout=15, verify=True)
                response.raise_for_status()
                soup = BeautifulSoup(response.text, 'html.parser')

                self.check_content_updates(soup, response)
                self.check_page_structure(soup)
                self.check_builder(soup, url, response)
            except requests.RequestException as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–∞–π—Ç–∞: {e}")
                self.results['–î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å'] = f"üî¥ –ù–µ–≥–∞—Ç–∏–≤ (—Å–∞–π—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω) {e}"

            self.check_owner(domain)
            self.check_reviews(domain)

            return self.generate_report()

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Å–∞–π—Ç–∞: {str(e)}"

    def normalize_and_check_protocol(self, url):
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è URL –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞"""
        # –ï—Å–ª–∏ –Ω–µ—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª–∞, –ø—Ä–æ–±—É–µ–º –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞
        if not url.startswith(('http://', 'https://')):
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º HTTPS
            https_url = 'https://' + url
            http_url = 'http://' + url

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç—É–ø–µ–Ω –ª–∏ —Å–∞–π—Ç –ø–æ HTTPS
            try:
                test_response = requests.head(https_url, headers=self.headers, timeout=5, verify=True)
                if test_response.status_code < 400:
                    logger.info(f"–°–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ HTTPS: {https_url}")
                    return https_url
            except:
                pass

            # –ï—Å–ª–∏ HTTPS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–±—É–µ–º HTTP
            try:
                test_response = requests.head(http_url, headers=self.headers, timeout=5)
                if test_response.status_code < 400:
                    logger.warning(f"–°–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω —Ç–æ–ª—å–∫–æ –ø–æ HTTP: {http_url}")
                    return http_url
            except:
                pass

            # –ï—Å–ª–∏ –æ–±–∞ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º HTTPS
            logger.warning(f"–°–∞–π—Ç –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º HTTPS –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {https_url}")
            return https_url

        return url

    def check_https_security(self, url, domain):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ HTTPS —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"""
        try:
            parsed_url = urlparse(url)
            scheme = parsed_url.scheme.lower()

            if scheme == 'https':
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ SSL/TLS —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞
                ssl_checks = self.check_ssl_certificate(domain)

                if ssl_checks['valid']:
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è HTTPS
                    score = 0
                    details = []

                    if ssl_checks['days_until_expiry'] > 30:
                        score += 1
                        details.append(f"—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –µ—â—ë {ssl_checks['days_until_expiry']} –¥–Ω–µ–π")
                    else:
                        details.append(f"‚ö†Ô∏è —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç –∏—Å—Ç–µ–∫–∞–µ—Ç —á–µ—Ä–µ–∑ {ssl_checks['days_until_expiry']} –¥–Ω–µ–π")

                    if ssl_checks['issuer_trusted']:
                        score += 1
                        details.append("–¥–æ–≤–µ—Ä–µ–Ω–Ω—ã–π –∏–∑–¥–∞—Ç–µ–ª—å")
                    else:
                        details.append("‚ö†Ô∏è –∏–∑–¥–∞—Ç–µ–ª—å –Ω–µ –∏–∑ –¥–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö")

                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–¥–∏—Ä–µ–∫—Ç–∞ —Å HTTP –Ω–∞ HTTPS
                    if self.check_http_to_https_redirect(domain):
                        score += 1
                        details.append("–µ—Å—Ç—å —Ä–µ–¥–∏—Ä–µ–∫—Ç —Å HTTP –Ω–∞ HTTPS")
                    else:
                        details.append("–Ω–µ—Ç —Ä–µ–¥–∏—Ä–µ–∫—Ç–∞ —Å HTTP –Ω–∞ HTTPS")

                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ HSTS
                    if self.check_hsts(domain):
                        score += 1
                        details.append("–≤–∫–ª—é—á–µ–Ω HSTS")

                    if score >= 3:
                        self.results['HTTPS –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å'] = f'üü¢ –ù–µ –Ω–µ–≥–∞—Ç–∏–≤ ({", ".join(details)})'
                    elif score >= 1:
                        self.results['HTTPS –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å'] = f'üü° –ù–µ–≥–∞—Ç–∏–≤ ({", ".join(details)})'
                    else:
                        self.results['HTTPS –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å'] = f'üî¥ –ù–µ–≥–∞—Ç–∏–≤ ({", ".join(details)})'
                else:
                    self.results['HTTPS –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å'] = f'üî¥ –ù–µ–≥–∞—Ç–∏–≤ (–ø—Ä–æ–±–ª–µ–º—ã —Å SSL: {ssl_checks["error"]})'
            else:
                # HTTP —Å–∞–π—Ç
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª–∏ —Å–∞–π—Ç HTTPS
                https_available = self.check_https_available(domain)

                if https_available:
                    self.results['HTTPS –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å'] = 'üî¥ –ù–µ–≥–∞—Ç–∏–≤ (—Å–∞–π—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç HTTP, –Ω–æ HTTPS –¥–æ—Å—Ç—É–ø–µ–Ω!)'
                else:
                    self.results['HTTPS –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å'] = 'üî¥ –ù–µ–≥–∞—Ç–∏–≤ (—Å–∞–π—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ–∑–∞—â–∏—â–µ–Ω–Ω—ã–π HTTP)'

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ HTTPS: {e}")
            self.results['HTTPS –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å'] = f'üü° –ù–µ–≥–∞—Ç–∏–≤ (–æ—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {str(e)[:50]})'

    def check_ssl_certificate(self, domain):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ SSL —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞"""
        try:
            # –£–±–∏—Ä–∞–µ–º –ø–æ—Ä—Ç –µ—Å–ª–∏ –µ—Å—Ç—å
            clean_domain = domain.split(':')[0]

            context = ssl.create_default_context()
            with socket.create_connection((clean_domain, 443), timeout=5) as sock:
                with context.wrap_socket(sock, server_hostname=clean_domain) as ssock:
                    cert = ssock.getpeercert()

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è
                    not_after_str = cert['notAfter']
                    not_after = datetime.strptime(not_after_str, '%b %d %H:%M:%S %Y %Z')
                    days_until_expiry = (not_after - datetime.now()).days

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–¥–∞—Ç–µ–ª—è
                    issuer = dict(x[0] for x in cert['issuer'])
                    issuer_name = issuer.get('organizationName', 'Unknown')

                    # –°–ø–∏—Å–æ–∫ –¥–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –∏–∑–¥–∞—Ç–µ–ª–µ–π
                    trusted_issuers = [
                        'Let\'s Encrypt', 'DigiCert', 'GlobalSign',
                        'Comodo', 'Sectigo', 'GoDaddy',
                        'Amazon', 'Google Trust Services'
                    ]

                    issuer_trusted = any(trusted in issuer_name for trusted in trusted_issuers)

                    return {
                        'valid': True,
                        'days_until_expiry': days_until_expiry,
                        'issuer': issuer_name,
                        'issuer_trusted': issuer_trusted,
                        'not_after': not_after_str
                    }

        except ssl.SSLCertVerificationError as e:
            return {'valid': False, 'error': f'–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞: {str(e)}'}
        except socket.timeout:
            return {'valid': False, 'error': '–¢–∞–π–º–∞—É—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è'}
        except ConnectionRefusedError:
            return {'valid': False, 'error': '–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–æ'}
        except Exception as e:
            return {'valid': False, 'error': f'–û—à–∏–±–∫–∞: {str(e)[:50]}'}

    def check_https_available(self, domain):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –¥–æ—Å—Ç—É–ø–µ–Ω –ª–∏ —Å–∞–π—Ç –ø–æ HTTPS"""
        try:
            https_url = f"https://{domain}"
            response = requests.head(https_url, headers=self.headers, timeout=5, verify=True)
            return response.status_code < 400
        except:
            return False

    def check_http_to_https_redirect(self, domain):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ–¥–∏—Ä–µ–∫—Ç —Å HTTP –Ω–∞ HTTPS"""
        try:
            http_url = f"http://{domain}"
            response = requests.get(http_url, headers=self.headers, timeout=5, allow_redirects=True)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª –ª–∏ —Ä–µ–¥–∏—Ä–µ–∫—Ç –Ω–∞ HTTPS
            for resp in response.history:
                if resp.is_redirect and 'https://' in resp.headers.get('Location', ''):
                    return True

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π URL
            final_url = response.url
            return final_url.startswith('https://')
        except:
            return False

    def check_hsts(self, domain):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ HSTS –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
        try:
            https_url = f"https://{domain}"
            response = requests.head(https_url, headers=self.headers, timeout=5, verify=True)

            hsts_header = response.headers.get('Strict-Transport-Security', '')
            return 'max-age' in hsts_header.lower()
        except:
            return False

    def is_valid_url(self, url):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ URL"""
        pattern = re.compile(
            r'^(https?://)?'  # –ø—Ä–æ—Ç–æ–∫–æ–ª
            r'((([a-z\d]([a-z\d-]*[a-z\d])*)\.)+[a-z]{2,}|'  # –¥–æ–º–µ–Ω
            r'((\d{1,3}\.){3}\d{1,3}))'  # –∏–ª–∏ IP
            r'(:\d+)?'  # –ø–æ—Ä—Ç
            r'(/[-a-z\d%_.~+]*)*'  # –ø—É—Ç—å
            r'(\?[;&a-z\d%_.~+=-]*)?'  # query string
            r'(#[-a-z\d_]*)?$', re.IGNORECASE)
        return pattern.match(url) is not None

    def extract_domain(self, url):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–æ–º–µ–Ω–∞ –∏–∑ URL"""
        parsed = urlparse(url)
        return parsed.netloc or parsed.path

    def check_domain_age(self, domain):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–æ–∑—Ä–∞—Å—Ç–∞ –¥–æ–º–µ–Ω–∞"""
        try:
            w = whois.whois(domain)
            creation_date = w.creation_date

            if isinstance(creation_date, list):
                creation_date = creation_date[0]

            if creation_date:
                age = datetime.now() - creation_date
                days = age.days
                months = days // 30

                if days < 120:  # 4 –º–µ—Å—è—Ü–∞
                    self.results['–í–æ–∑—Ä–∞—Å—Ç –¥–æ–º–µ–Ω–∞'] = f'üî¥ –ù–µ–≥–∞—Ç–∏–≤ ({months} –º–µ—Å.)'
                else:
                    self.results['–í–æ–∑—Ä–∞—Å—Ç –¥–æ–º–µ–Ω–∞'] = f'üü¢ –ù–µ –Ω–µ–≥–∞—Ç–∏–≤ ({months} –º–µ—Å.)'
            else:
                self.results['–í–æ–∑—Ä–∞—Å—Ç –¥–æ–º–µ–Ω–∞'] = 'üü° –ù–µ–≥–∞—Ç–∏–≤ (–Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å)'

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ WHOIS: {e}")
            self.results['–í–æ–∑—Ä–∞—Å—Ç –¥–æ–º–µ–Ω–∞'] = 'üü° –ù–µ–≥–∞—Ç–∏–≤ (–æ—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏)'

    # ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π ...
    def check_content_updates(self, soup, response):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        try:
            current_year = datetime.now().year
            current_month = datetime.now().month

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞—Ç—É –≤ headers
            if 'last-modified' in response.headers:
                last_modified = response.headers['last-modified']
                self.results['–û–±–Ω–æ–≤–ª–µ–Ω–∏—è'] = f'üü¢ –ù–µ –Ω–µ–≥–∞—Ç–∏–≤ (–ø–æ—Å–ª–µ–¥–Ω–µ–µ: {last_modified[:20]})'
                return

            # –ò—â–µ–º –¥–∞—Ç—ã –≤ —Ç–µ–∫—Å—Ç–µ
            text = soup.get_text()
            date_patterns = [
                r'\b\d{2}[./-]\d{2}[./-]\d{4}\b',  # DD.MM.YYYY
                r'\b\d{4}[./-]\d{2}[./-]\d{2}\b',  # YYYY-MM-DD
                r'\b(—è–Ω–≤–∞—Ä—è|—Ñ–µ–≤—Ä–∞–ª—è|–º–∞—Ä—Ç–∞|–∞–ø—Ä–µ–ª—è|–º–∞—è|–∏—é–Ω—è|–∏—é–ª—è|–∞–≤–≥—É—Å—Ç–∞|—Å–µ–Ω—Ç—è–±—Ä—è|–æ–∫—Ç—è–±—Ä—è|–Ω–æ—è–±—Ä—è|–¥–µ–∫–∞–±—Ä—è)\s+\d{4}\b',
            ]

            found_dates = []
            for pattern in date_patterns:
                dates = re.findall(pattern, text, re.IGNORECASE)
                found_dates.extend(dates)

            # –ò—â–µ–º copyright
            copyright_pattern = r'¬©.*?(\d{4})|copyright.*?(\d{4})'
            copyright_matches = re.findall(copyright_pattern, text, re.IGNORECASE)
            for match in copyright_matches:
                year = match[0] or match[1]
                if year:
                    found_dates.append(year)

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –¥–∞—Ç—ã
            recent_dates = []
            for date_str in found_dates[:10]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 10 –¥–∞—Ç
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–æ–¥
                year_match = re.search(r'(\d{4})', date_str)
                if year_match:
                    year = int(year_match.group(1))
                    if year >= current_year - 1:
                        recent_dates.append(year)

            if recent_dates:
                self.results['–û–±–Ω–æ–≤–ª–µ–Ω–∏—è'] = f'üü¢ –ù–µ –Ω–µ–≥–∞—Ç–∏–≤ (–æ–±–Ω–æ–≤–ª–µ–Ω –≤ {max(recent_dates)})'
            else:
                self.results['–û–±–Ω–æ–≤–ª–µ–Ω–∏—è'] = 'üî¥ –ù–µ–≥–∞—Ç–∏–≤ (–Ω–µ—Ç —Å–≤–µ–∂–∏—Ö –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π)'

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π: {e}")
            self.results['–û–±–Ω–æ–≤–ª–µ–Ω–∏—è'] = 'üü° –ù–µ–≥–∞—Ç–∏–≤ (–æ—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏)'

    def check_page_structure(self, soup):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å–∞–π—Ç–∞"""
        try:
            # –ò—â–µ–º –Ω–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
            nav_elements = soup.find_all(['nav', 'ul', 'ol', 'menu'])

            # –°—á–∏—Ç–∞–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å—Å—ã–ª–∫–∏
            links = soup.find_all('a', href=True)
            internal_links = 0
            for link in links:
                href = link.get('href', '')
                if href.startswith(('#', '/')) or 'http' not in href:
                    internal_links += 1

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–æ—Ä–º (–ø—Ä–∏–∑–Ω–∞–∫ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏)
            forms = soup.find_all('form')

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if len(nav_elements) < 1 and internal_links < 8 and len(forms) < 1:
                self.results['–°—Ç—Ä—É–∫—Ç—É—Ä–∞'] = 'üî¥ –ù–µ–≥–∞—Ç–∏–≤ (–æ–¥–Ω–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω—ã–π)'
            else:
                self.results['–°—Ç—Ä—É–∫—Ç—É—Ä–∞'] = f'üü¢ –ù–µ –Ω–µ–≥–∞—Ç–∏–≤ ({internal_links} —Å—Å—ã–ª–æ–∫, {len(nav_elements)} –Ω–∞–≤–∏–≥–∞—Ü–∏–π)'

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã: {e}")
            self.results['–°—Ç—Ä—É–∫—Ç—É—Ä–∞'] = 'üü° –ù–µ–≥–∞—Ç–∏–≤ (–æ—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏)'

    def check_builder(self, soup, url, response):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–∞"""
        try:
            domain = self.extract_domain(url).lower()
            page_text = str(soup).lower()
            html_text = response.text.lower()

            # –ü—Ä–∏–∑–Ω–∞–∫–∏ –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–æ–≤
            free_builders = {
                'Wix': ['wix', 'wixpress', 'wixsite.com'],
                'Weebly': ['weebly', 'weebly.com'],
                'WordPress.com': ['wordpress.com', 'wp.com', 'wp-content'],
                'Blogger': ['blogger', 'blogspot'],
                'Tilda': ['tilda', 'tilda.ws', 'tilda.cc'],
                'Ucoz': ['ucoz', 'ucoz.ru'],
                'Jimdo': ['jimdo', 'jimdosite'],
                'Webnode': ['webnode'],
            }

            # –ü—Ä–∏–∑–Ω–∞–∫–∏ –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö —Ö–æ—Å—Ç–∏–Ω–≥–æ–≤
            free_hosting = [
                'github.io', 'netlify.app', 'vercel.app',
                'herokuapp.com', '000webhostapp.com',
                'glitch.me', 'repl.co', 'firebaseapp.com',
                'surge.sh', 'web.app'
            ]

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä—ã
            for builder_name, keywords in free_builders.items():
                if any(keyword in domain for keyword in keywords) or \
                        any(keyword in html_text for keyword in keywords):
                    self.results['–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä'] = f'üî¥ –ù–µ–≥–∞—Ç–∏–≤ ({builder_name})'
                    return

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Ö–æ—Å—Ç–∏–Ω–≥
            if any(host in domain for host in free_hosting):
                self.results['–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä'] = 'üî¥ –ù–µ–≥–∞—Ç–∏–≤ (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Ö–æ—Å—Ç–∏–Ω–≥)'
                return

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç–∞-—Ç–µ–≥–∏
            meta_generator = soup.find('meta', {'name': 'generator'})
            if meta_generator and meta_generator.get('content'):
                content = meta_generator['content'].lower()
                for builder_name, keywords in free_builders.items():
                    if any(keyword in content for keyword in keywords):
                        self.results['–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä'] = f'üî¥ –ù–µ–≥–∞—Ç–∏–≤ ({builder_name})'
                        return

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º JavaScript —Ñ–∞–π–ª—ã
            scripts = soup.find_all('script', src=True)
            for script in scripts:
                src = script.get('src', '').lower()
                for builder_name, keywords in free_builders.items():
                    if any(keyword in src for keyword in keywords):
                        self.results['–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä'] = f'üî¥ –ù–µ–≥–∞—Ç–∏–≤ ({builder_name})'
                        return

            self.results['–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä'] = 'üü¢ –ù–µ –Ω–µ–≥–∞—Ç–∏–≤'

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–∞: {e}")
            self.results['–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä'] = 'üü° –ù–µ–≥–∞—Ç–∏–≤ (–æ—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏)'

    def check_owner(self, domain):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–ª–∞–¥–µ–ª—å—Ü–∞ –¥–æ–º–µ–Ω–∞"""
        try:
            w = whois.whois(domain)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é
            if w.org:
                self.results['–í–ª–∞–¥–µ–ª–µ—Ü'] = f'üü¢ –ù–µ –Ω–µ–≥–∞—Ç–∏–≤ (–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è: {w.org[:50]})'
                return

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–º–µ–Ω–∏ —Ñ–∏–∑–∏—á–µ—Å–∫–æ–≥–æ –ª–∏—Ü–∞
            if w.name:
                name = str(w.name)
                # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è —Ä—É—Å—Å–∫–∏—Ö –§–ò–û
                ru_name_pattern = r'^[–ê-–Ø–Å][–∞-—è—ë]+\s+[–ê-–Ø–Å][–∞-—è—ë]+(\s+[–ê-–Ø–Å][–∞-—è—ë]+)?$'
                # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö –∏–º–µ–Ω
                en_name_pattern = r'^[A-Z][a-z]+\s+[A-Z][a-z]+$'

                if re.match(ru_name_pattern, name) or re.match(en_name_pattern, name):
                    self.results['–í–ª–∞–¥–µ–ª–µ—Ü'] = f'üî¥ –ù–µ–≥–∞—Ç–∏–≤ (—á–∞—Å—Ç–Ω–æ–µ –ª–∏—Ü–æ: {name[:30]})'
                else:
                    self.results['–í–ª–∞–¥–µ–ª–µ—Ü'] = f'üü° –ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ ({name[:30]})'
            else:
                self.results['–í–ª–∞–¥–µ–ª–µ—Ü'] = 'üü° –ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ'

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤–ª–∞–¥–µ–ª—å—Ü–∞: {e}")
            self.results['–í–ª–∞–¥–µ–ª–µ—Ü'] = 'üü° –ù–µ–≥–∞—Ç–∏–≤ (–æ—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏)'

    def check_reviews(self, domain):
        """–ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç–∑—ã–≤–æ–≤"""
        try:
            # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (–≤ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –Ω—É–∂–Ω–æ API)
            clean_domain = domain.replace('www.', '').split('/')[0]

            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –≤—ã–∑–æ–≤ API –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—Ç–∑—ã–≤–æ–≤
            # –ù–∞–ø—Ä–∏–º–µ—Ä: trustpilot, –Ø–Ω–¥–µ–∫—Å.–û—Ç–∑—ã–≤—ã –∏ —Ç.–¥.

            # –í—Ä–µ–º–µ–Ω–Ω–∞—è –∑–∞–≥–ª—É—à–∫–∞
            self.results['–û—Ç–∑—ã–≤—ã'] = 'üü° –¢—Ä–µ–±—É–µ—Ç —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏'
            # self.results['–û—Ç–∑—ã–≤—ã'] = 'üî¥ –ù–µ–≥–∞—Ç–∏–≤ (–Ω–µ—Ç –æ—Ç–∑—ã–≤–æ–≤)'
            # self.results['–û—Ç–∑—ã–≤—ã'] = 'üü¢ –ù–µ –Ω–µ–≥–∞—Ç–∏–≤ (–µ—Å—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–∑—ã–≤—ã)'

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—Ç–∑—ã–≤–æ–≤: {e}")
            self.results['–û—Ç–∑—ã–≤—ã'] = 'üü° –ù–µ–≥–∞—Ç–∏–≤ (–æ—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏)'

    def generate_report(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞"""
        negative_count = 0
        warning_count = 0

        for value in self.results.values():
            if 'üî¥' in value:
                negative_count += 1
            elif 'üü°' in value and '–ù–µ–≥–∞—Ç–∏–≤' in value:
                negative_count += 1
                warning_count += 1
            elif 'üü°' in value:
                warning_count += 1

        report = "üìä *–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —Å–∞–π—Ç–∞*\n\n"

        for key, value in self.results.items():
            report += f"‚Ä¢ *{key}*: {value}\n"

        report += "\n" + "=" * 40 + "\n\n"

        if negative_count >= 2:
            report += "‚ùå *–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø:* –ù–ï –ü–†–û–í–û–î–ò–¢–¨ –û–ü–ï–†–ê–¶–ò–ò –ù–ê –î–ê–ù–ù–û–ú –°–ê–ô–¢–ï\n\n"
            report += f"*–ü—Ä–∏—á–∏–Ω–∞:* {negative_count} –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤"
            if warning_count > 0:
                report += f" –∏ {warning_count} –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π"
        else:
            report += "‚ö†Ô∏è *–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø:* –ú–û–ñ–ù–û –ò–°–ü–û–õ–¨–ó–û–í–ê–¢–¨ –° –û–°–¢–û–†–û–ñ–ù–û–°–¢–¨–Æ\n\n"
            report += f"*–°—Ç–∞—Ç—É—Å:* {negative_count} –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤"
            if warning_count > 0:
                report += f", {warning_count} –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π"

        return report